import { NextRequest, NextResponse } from 'next/server';
import { jobStorage } from '../../../lib/job-storage';

interface AnalyzeRequest {
  url: string;
  options?: {
    screenshot?: boolean;
    lighthouse?: boolean;
    mobile?: boolean;
    timeout?: number;
  };
}

export async function POST(request: NextRequest) {
  try {
    const body: AnalyzeRequest = await request.json();
    
    // Validate request
    if (!body.url) {
      return NextResponse.json(
        { error: 'URL is required' },
        { status: 400 }
      );
    }

    // Validate URL format
    try {
      new URL(body.url);
    } catch {
      return NextResponse.json(
        { error: 'Invalid URL format' },
        { status: 400 }
      );
    }

    // Generate unique job ID with encoded URL for recovery
    const urlBase64 = Buffer.from(body.url).toString('base64').replace(/[^A-Za-z0-9]/g, '');
    const jobId = `job_${Date.now()}_${urlBase64.slice(0, 20)}_${Math.random().toString(36).substr(2, 5)}`;
    
    console.log(`ğŸ” Starting analysis for ${body.url} (Job ID: ${jobId})`);

    // Default options
    const options = {
      screenshot: body.options?.screenshot !== false,
      lighthouse: body.options?.lighthouse !== false,
      mobile: body.options?.mobile || false,
      timeout: body.options?.timeout || 30000,
      ...body.options
    };

    // Store job in storage (KV or in-memory fallback)
    if (process.env.KV_REST_API_URL && process.env.KV_REST_API_TOKEN) {
      try {
        await fetch(`${process.env.KV_REST_API_URL}/set/${jobId}`, {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${process.env.KV_REST_API_TOKEN}`,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            status: 'pending',
            url: body.url,
            options,
            createdAt: new Date().toISOString()
          })
        });
      } catch (error) {
        console.error('Failed to store job in KV:', error);
      }
    } else {
      // Use in-memory storage as fallback
      console.log('ğŸ“¦ Using in-memory job storage');
      jobStorage.set(jobId, {
        url: body.url,
        status: 'pending',
        data: { options }
      });
    }

    // Start analysis in background
    processAnalysis(jobId, body.url, options).catch(error => {
      console.error(`Analysis failed for job ${jobId}:`, error);
      updateJobStatus(jobId, 'error', { error: error.message });
    });

    return NextResponse.json({
      jobId,
      status: 'pending',
      message: 'Analysis started successfully'
    });

  } catch (error) {
    console.error('Analyze API error:', error);
    return NextResponse.json(
      { error: 'Internal server error' },
      { status: 500 }
    );
  }
}

async function processAnalysis(jobId: string, url: string, options: any) {
  try {
    console.log(`ğŸ”„ Processing analysis for job ${jobId}`);
    
    // Update status to processing
    await updateJobStatus(jobId, 'processing', { 
      step: 'Starting analysis...',
      progress: 10
    });

    // Take screenshot if requested
    let screenshotUrl = null;
    if (options.screenshot) {
      try {
        await updateJobStatus(jobId, 'processing', { 
          step: 'ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’æ’®å½±ä¸­...',
          progress: 25
        });
        
        screenshotUrl = await takeScreenshot(url, options);
        console.log(`ğŸ“¸ Screenshot taken: ${screenshotUrl}`);
      } catch (error) {
        console.warn('âš ï¸ Screenshot failed:', error);
        // Continue without screenshot
      }
    }

    // Implement fallback chain: Railway -> Local -> Mock
    let scrapeData = null;
    let scrapeSource = '';

    // Try 1: Railway scraper service
    const railwayUrl = process.env.SCRAPER_SERVICE_URL;
    if (railwayUrl) {
      try {
        console.log('ğŸš‚ Trying Railway scraper service...');
        await updateJobStatus(jobId, 'processing', { 
          step: 'Railway ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹ã‚’è©¦è¡Œä¸­...',
          progress: 30
        });

        const railwayResponse = await fetch(`${railwayUrl}/api/scrape`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({ url, options }),
          signal: AbortSignal.timeout(options.timeout + 5000)
        });

        if (railwayResponse.ok) {
          scrapeData = await railwayResponse.json();
          scrapeSource = 'Railway';
          console.log('âœ… Successfully scraped via Railway service');
        } else {
          console.warn(`âš ï¸ Railway service failed: ${railwayResponse.status} - ${railwayResponse.statusText}`);
        }
      } catch (railwayError) {
        if (railwayError instanceof Error && railwayError.name === 'AbortError') {
          console.warn('âš ï¸ Railway service timeout');
        } else {
          console.warn('âš ï¸ Railway service error:', railwayError);
        }
      }
    }

    // Try 2: Local scraper service (if Railway failed)
    if (!scrapeData) {
      try {
        console.log('ğŸ  Trying local scraper service...');
        await updateJobStatus(jobId, 'processing', { 
          step: 'ãƒ­ãƒ¼ã‚«ãƒ«ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹ã‚’è©¦è¡Œä¸­...',
          progress: 40
        });

        const localResponse = await fetch(`${process.env.NEXTAUTH_URL || 'http://localhost:3000'}/api/scrape-local`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({ url, options }),
          signal: AbortSignal.timeout(options.timeout + 10000)
        });

        if (localResponse.ok) {
          scrapeData = await localResponse.json();
          scrapeSource = 'Local';
          console.log('âœ… Successfully scraped via local service');
        } else {
          console.warn(`âš ï¸ Local scraper failed: ${localResponse.status} - ${localResponse.statusText}`);
        }
      } catch (localError) {
        if (localError instanceof Error && localError.name === 'AbortError') {
          console.warn('âš ï¸ Local scraper timeout');
        } else {
          console.warn('âš ï¸ Local scraper error:', localError);
        }
      }
    }

    // Try 3: Fallback to mock data (if both failed)
    if (!scrapeData) {
      console.warn(`âš ï¸ All scraping methods failed, falling back to mock analysis`);
      
      // Still perform analysis with mock data but using the actual URL
      await updateJobStatus(jobId, 'processing', { 
        step: 'ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼ - ãƒ¢ãƒƒã‚¯åˆ†æã‚’å®Ÿè¡Œä¸­...',
        progress: 70
      });
      
      // Create mock scrape data with the actual URL
      scrapeData = {
        scrapeData: {
          url,
          pageData: {
            url,
            title: `${url} ã®åˆ†æçµæœ`,
            description: 'ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹ã‚¨ãƒ©ãƒ¼ã®ãŸã‚ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨',
            headings: { h1: [], h2: [], h3: [] },
            images: [],
            links: [],
            forms: [],
            mobileOptimized: false,
            hasSSL: url.startsWith('https')
          },
          conversionElements: { ctaButtons: [] },
          performance: { loadTime: 3000 }
        },
        lighthouseData: null
      };
      scrapeSource = 'Mock';
    }

    // Continue with analysis using scraped data (real or mock)
    await updateJobStatus(jobId, 'processing', { 
      step: 'AIåˆ†æã‚’å®Ÿè¡Œä¸­...',
      progress: 60
    });

    const analysisData = await runAIAnalysis(scrapeData, screenshotUrl);
    
    await updateJobStatus(jobId, 'processing', { 
      step: 'ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...',
      progress: 90
    });

    // Format final result based on data source
    let result;
    if (scrapeSource === 'Mock') {
      result = {
        url,
        timestamp: new Date().toISOString(),
        overallScore: analysisData.overallScore,
        categories: analysisData.categories,
        criticalIssues: analysisData.criticalIssues,
        opportunities: analysisData.opportunities,
        detailedInstructions: [], // ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨æ™‚ã¯è©³ç´°æŒ‡ç¤ºã‚’éè¡¨ç¤º
        rawData: {
          scrapeData: scrapeData.scrapeData,
          lighthouseData: scrapeData.lighthouseData
        },
        note: 'ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼ã®ãŸã‚ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦åˆ†æã‚’å®Ÿè¡Œã—ã¾ã—ãŸ',
        error: {
          type: 'scraping_failed',
          message: 'å®Ÿéš›ã®ãƒšãƒ¼ã‚¸ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ä¸€èˆ¬çš„ãªåˆ†æçµæœã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚',
          suggestion: 'ã‚µã‚¤ãƒˆãŒã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã€å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚'
        }
      };
    } else {
      result = {
        url,
        timestamp: new Date().toISOString(),
        overallScore: analysisData.overallScore,
        categories: analysisData.categories,
        criticalIssues: analysisData.criticalIssues,
        opportunities: analysisData.opportunities,
        detailedInstructions: analysisData.detailedInstructions || [], // è©³ç´°æ”¹å–„æŒ‡ç¤ºã‚’å«ã‚ã‚‹
        rawData: {
          scrapeData: scrapeData.scrapeData,
          lighthouseData: scrapeData.lighthouseData
        },
        dataSource: scrapeSource // å®Ÿéš›ã«ä½¿ç”¨ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’è¿½è¨˜
      };
    }

    // Update job with final result
    await updateJobStatus(jobId, 'completed', result);
    console.log(`âœ… Analysis completed for job ${jobId} - URL: ${url}, Source: ${scrapeSource}, Score: ${result.overallScore}`);

  } catch (error) {
    console.error(`âŒ Analysis failed for job ${jobId}:`, error);
    await updateJobStatus(jobId, 'error', { 
      error: error instanceof Error ? error.message : 'Unknown error'
    });
  }
}

async function runAIAnalysis(data: any, screenshotUrl: string | null = null) {
  // Enhanced AI analysis using the Analysis Engine
  const { scrapeData, lighthouseData } = data;
  
  console.log('ğŸ§  Running comprehensive AI analysis with 100+ checkpoints...');

  // Import Analysis Engine (dynamic import to avoid build issues)
  const { AnalysisEngine } = await import('../../../lib/analysis/engine');
  
  // Prepare analysis input in the expected format
  const analysisInput = {
    scrapedData: {
      url: scrapeData?.pageData?.url || scrapeData?.url || 'unknown',
      title: scrapeData?.pageData?.title || 'Untitled',
      description: scrapeData?.pageData?.description || '',
      headings: scrapeData?.pageData?.headings || { h1: [], h2: [], h3: [] },
      images: scrapeData?.pageData?.images || [],
      links: scrapeData?.pageData?.links || [],
      forms: scrapeData?.pageData?.forms || [],
      ctaElements: scrapeData?.conversionElements?.ctaButtons || [],
      socialProof: [],
      loadTime: scrapeData?.performance?.loadTime || 0,
      mobileOptimized: scrapeData?.pageData?.mobileOptimized || false,
      hasSSL: scrapeData?.pageData?.hasSSL || false,
      screenshot: screenshotUrl || undefined
    },
    lighthouseData: lighthouseData || {
      scores: {
        performance: 75,
        accessibility: 80,
        bestPractices: 85,
        seo: 80
      },
      coreWebVitals: {},
      opportunities: [],
      accessibilityIssues: [],
      seoIssues: []
    },
    options: {
      includeScreenshots: true,
      mobileAnalysis: true,
      deepAnalysis: true
    }
  };

  // Run the comprehensive analysis
  const engine = new AnalysisEngine();
  const analysisResult = await engine.analyzeWebsite(analysisInput);

  // Return the comprehensive analysis result
  return {
    overallScore: analysisResult.overallScore,
    categories: analysisResult.categories,
    criticalIssues: analysisResult.criticalIssues,
    opportunities: analysisResult.opportunities,
    insights: analysisResult.insights,
    recommendations: analysisResult.recommendations,
    checkpoints: analysisResult.checkpoints,
    detailedInstructions: analysisResult.detailedInstructions // è©³ç´°æ”¹å–„æŒ‡ç¤ºã‚’è¿½åŠ 
  };
}

async function updateJobStatus(jobId: string, status: string, data: any) {
  // Update in KV if available
  if (process.env.KV_REST_API_URL && process.env.KV_REST_API_TOKEN) {
    try {
      await fetch(`${process.env.KV_REST_API_URL}/set/${jobId}`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${process.env.KV_REST_API_TOKEN}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          status,
          data,
          updatedAt: new Date().toISOString()
        })
      });
    } catch (error) {
      console.error('Failed to update job status in KV:', error);
    }
  } else {
    // Use in-memory storage as fallback
    jobStorage.set(jobId, {
      status: status as any,
      data
    });
  }
  
  console.log(`ğŸ“Š Job ${jobId} status updated: ${status}`);
}

// ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆæ’®å½±é–¢æ•°
async function takeScreenshot(url: string, options: any): Promise<string | null> {
  try {
    console.log(`ğŸ“¸ Taking screenshot for ${url}`);
    
    // æ–¹æ³•1: å¤–éƒ¨ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚µãƒ¼ãƒ“ã‚¹ï¼ˆURLScreenshot.comãªã©ï¼‰
    const screenshotServiceUrl = process.env.SCREENSHOT_SERVICE_URL;
    
    if (screenshotServiceUrl) {
      console.log('ğŸŒ Using external screenshot service');
      const response = await fetch(`${screenshotServiceUrl}/screenshot`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ 
          url, 
          viewport: { width: 1200, height: 800 },
          fullPage: true,
          timeout: 30000,
          quality: 90
        }),
        signal: AbortSignal.timeout(35000)
      });
      
      if (response.ok) {
        const result = await response.json();
        console.log(`âœ… Screenshot captured via external service: ${result.screenshotUrl}`);
        return result.screenshotUrl;
      } else {
        console.warn(`âš ï¸ External screenshot service failed: ${response.status}`);
      }
    }
    
    // æ–¹æ³•2: ç„¡æ–™ã®APIã‚µãƒ¼ãƒ“ã‚¹ï¼ˆScreenshotAPIã€ApiFlashç­‰ï¼‰
    const apiKey = process.env.SCREENSHOT_API_KEY;
    if (apiKey) {
      console.log('ğŸ”‘ Using Screenshot API service');
      try {
        // Screenshot API (https://screenshotapi.net/) ã®ä¾‹
        const apiUrl = `https://shot.screenshotapi.net/screenshot`;
        const response = await fetch(apiUrl, {
          method: 'POST',
          headers: { 
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${apiKey}`
          },
          body: JSON.stringify({
            url,
            width: 1200,
            height: 800,
            format: 'png',
            full_page: true,
            fresh: true
          }),
          signal: AbortSignal.timeout(30000)
        });
        
        if (response.ok) {
          const result = await response.json();
          if (result.screenshot) {
            console.log('âœ… Screenshot captured via API service');
            return result.screenshot; // Base64ã¾ãŸã¯URL
          }
        } else {
          console.warn(`âš ï¸ Screenshot API failed: ${response.status}`);
        }
      } catch (apiError) {
        console.warn('âš ï¸ Screenshot API error:', apiError);
      }
    }
    
    // æ–¹æ³•3: ä»–ã®ç„¡æ–™APIã‚µãƒ¼ãƒ“ã‚¹ã‚’è©¦ã™
    console.log('ğŸ“¸ Trying alternative screenshot services');
    // å°†æ¥çš„ã«è¿½åŠ ã®ç„¡æ–™ã‚µãƒ¼ãƒ“ã‚¹ã‚’å®Ÿè£…
    
    // æ–¹æ³•4: é«˜å“è³ªãªãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ç”»åƒ
    console.log('ğŸ“¸ Generating enhanced placeholder screenshot');
    return generateEnhancedPlaceholder(url);
    
  } catch (error) {
    console.error('Screenshot capture failed:', error);
    return generateEnhancedPlaceholder(url);
  }
}


// é«˜å“è³ªãªãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ç”»åƒç”Ÿæˆ
function generateEnhancedPlaceholder(url: string): string {
  const domain = new URL(url).hostname;
  const encodedDomain = encodeURIComponent(domain);
  
  // ã‚ˆã‚Šè©³ç´°ãªãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ç”»åƒã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ç”¨
  return `https://via.placeholder.com/1200x800/f8f9fa/6c757d?text=ğŸ–¥ï¸+${encodedDomain}+%0A%0AğŸ“¸+ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆæ’®å½±ä¸­...%0Aå®Ÿéš›ã®ç”»é¢ãŒè¡¨ç¤ºã•ã‚Œã¾ã™`;
}